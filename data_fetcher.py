# data_fetcher.py
import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta
import logging
from typing import Dict, Union, Optional

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (logging)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class StockDataFetcher:
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© ÙƒØ§Ø¦Ù† Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ù‡Ù…"""
        self.cache = {}  # Ø°Ø§ÙƒØ±Ø© ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        
    def _get_cached_data(self, key: str) -> Optional[Union[pd.DataFrame, Dict]]:
        """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©"""
        if key in self.cache:
            cached_data, timestamp = self.cache[key]
            if (datetime.now() - timestamp).seconds < 300:  # 5 Ø¯Ù‚Ø§Ø¦Ù‚ ØµÙ„Ø§Ø­ÙŠØ©
                return cached_data
        return None
    
    def _set_cache_data(self, key: str, data: Union[pd.DataFrame, Dict]) -> None:
        """ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©"""
        self.cache[key] = (data, datetime.now())
    
    def fetch_delta_data(self, symbols: Dict[str, str], days: int = 7) -> pd.DataFrame:
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù„ØªØ§ Ù„Ù„Ø£Ø³Ù‡Ù…"""
        try:
            today = datetime.today()
            start_date = today - timedelta(days=days)
            cache_key = f"delta_{'_'.join(symbols.values())}_{days}"
            
            cached_data = self._get_cached_data(cache_key)
            if cached_data is not None:
                logger.info("âœ… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù„ØªØ§ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©")
                return cached_data
            
            logger.info(f"ğŸ“¥ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù„ØªØ§ Ù…Ù† Yahoo Finance Ù„Ù„ÙØªØ±Ø© {days} ÙŠÙˆÙ…")
            data = yf.download(
                list(symbols.values()),
                start=start_date,
                end=today,
                group_by='ticker',
                progress=False
            )
            
            if data.empty:
                logger.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø©")
                return pd.DataFrame()
            
            results = []
            for name, symbol in symbols.items():
                if symbol in data.columns.get_level_values(0):
                    adj_close = data[symbol]['Adj Close']
                    if not adj_close.empty:
                        delta = ((adj_close.iloc[-1] - adj_close.iloc[0]) / adj_close.iloc[0]) * 100
                        results.append({
                            'Symbol': symbol,
                            'Name': name,
                            'Delta (%)': round(delta, 2),
                            'Last Price': round(adj_close.iloc[-1], 2),
                            'Start Date': start_date.strftime('%Y-%m-%d'),
                            'End Date': today.strftime('%Y-%m-%d')
                        })
            
            df = pd.DataFrame(results).sort_values('Delta (%)', ascending=False)
            self._set_cache_data(cache_key, df)
            return df
            
        except Exception as e:
            logger.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù„ØªØ§: {str(e)}")
            return pd.DataFrame()
    
    def fetch_moving_averages(self, symbol: str, days: int = 365) -> Optional[Dict]:
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù…ØªØ­Ø±ÙƒØ© Ù„Ø³Ù‡Ù… Ù…Ø¹ÙŠÙ†"""
        try:
            today = datetime.today()
            start_date = today - timedelta(days=days)
            cache_key = f"ma_{symbol}_{days}"
            
            cached_data = self._get_cached_data(cache_key)
            if cached_data is not None:
                logger.info("âœ… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©")
                return cached_data
            
            logger.info(f"ğŸ“ˆ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù…ØªØ­Ø±ÙƒØ© Ù„Ù„Ø³Ù‡Ù… {symbol}")
            
            stock = yf.Ticker(symbol)
            try:
                info = stock.info
                if 'timezone' not in info:
                    logger.warning(f"âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ timezone Ù„Ù„Ø³Ù‡Ù… {symbol} â€” Ù‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† Ù…Ø¯Ø¹ÙˆÙ…Ù‹Ø§")
                    return None
            except Exception:
                logger.warning(f"âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³Ù‡Ù… {symbol}")
                return None

            stock_data = stock.history(start=start_date, end=today)
            
            if stock_data.empty:
                logger.warning(f"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø³Ù‡Ù… {symbol}")
                return None
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª
            stock_data['MA_50'] = stock_data['Close'].rolling(window=50, min_periods=1).mean()
            stock_data['MA_200'] = stock_data['Close'].rolling(window=200, min_periods=1).mean()
            
            latest = stock_data.iloc[-1]
            prev_close = stock_data.iloc[-2]['Close'] if len(stock_data) > 1 else latest['Close']
            
            result = {
                'symbol': symbol,
                'current_price': latest['Close'],
                'prev_close': prev_close,
                'year_high': stock_data['High'].max(),
                'year_low': stock_data['Low'].min(),
                'ma_50': latest['MA_50'],
                'ma_200': latest['MA_200'],
                'history': stock_data,
                'start_date': start_date,
                'end_date': today
            }
            
            self._set_cache_data(cache_key, result)
            return result
            
        except Exception as e:
            logger.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù…ØªØ­Ø±ÙƒØ© Ù„Ù„Ø³Ù‡Ù… {symbol}: {str(e)}")
            return None
